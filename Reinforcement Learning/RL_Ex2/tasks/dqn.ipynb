{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RLLBC Bonus Point Assignment II Part B\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 1.0.0, released 2022-06-24</div>\n",
    "For task instructions, refer to the assignment PDF.\n",
    "\n",
    "* The parts of the code you are to implement are indicated via `# TODO` comments.\n",
    "* You can use the `# Test code` cells to verify your implementation. However note that these are not the unit tests used for grading.\n",
    "* Some cells create export file in the `solution/` folder. _Include whole `solution/` folder in your submission_.\n",
    "* DO NOT CLEAR THE OUTPUT of the notebook you are submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gym\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create solution folder\n",
    "Path(\"solution/\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question B1 - Deep Q-Networks\n",
    "### a) Implement Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, mem_size, state_shape):\n",
    "        \"\"\"Initialization of the replay buffer.\n",
    "        \n",
    "        The memories have the following data types:\n",
    "            states: float32\n",
    "            next_states: float32\n",
    "            actions: int64\n",
    "            rewards: float32\n",
    "            is_terminal: bool\n",
    "\n",
    "        Args:\n",
    "            mem_size: Capacity of this buffer\n",
    "            state_shape: Shape of state and next_state\n",
    "        \"\"\"\n",
    "        self.mem_size = mem_size  # Capacity of the buffer\n",
    "        self.mem_cntr = 0         # Number of added elements\n",
    "        self.state_memory = np.zeros((self.mem_size, *state_shape), dtype=np.float32)\n",
    "        self.next_state_memory = np.zeros((self.mem_size, *state_shape), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool_)\n",
    "    \n",
    "    def is_filled(self):\n",
    "        \"\"\"Check if the memory is filled.\"\"\"\n",
    "        return buffer.mem_cntr >= buffer.mem_size\n",
    "\n",
    "    def add(self, state, action, reward, next_state, is_terminal):\n",
    "        \"\"\"Add one transition to the buffer.\n",
    "\n",
    "        Replaces the oldest transition in memory.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        if state in self.state_memory:\n",
    "            indexx = np.where(state in self.state_memory)\n",
    "        elif state not in self.state_memory:\n",
    "            indexx = min(np.where(self.state_memory.any(axis=1)==0)[0])\n",
    "            \n",
    "        self.state_memory[indexx] = state\n",
    "        self.next_state_memory[indexx] = next_state\n",
    "        self.action_memory[indexx] = action\n",
    "        self.reward_memory[indexx] = reward\n",
    "        self.terminal_memory[indexx] = is_terminal\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        \"\"\"Sample one batch from the memory.\"\"\"\n",
    "        # TODO\n",
    "        idx = np.random.choice(self.state_memory[:,0],batch_size,replace=False).astype(int)\n",
    "        states = self.state_memory[idx]\n",
    "        actions = self.action_memory[idx]\n",
    "        rewards = self.reward_memory[idx]\n",
    "        is_terminal = self.terminal_memory[idx]\n",
    "        next_states = self.next_state_memory[idx]\n",
    "        return states, actions, rewards, next_states, is_terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code\n",
    "_buffer = ReplayBuffer(10, (5, ))\n",
    "assert _buffer.mem_size == 10\n",
    "assert _buffer.mem_cntr == 0\n",
    "for i in range(10):  # Fill test values\n",
    "    _buffer.add(np.arange(5) + i, 5 + i, 6 + i, 7 + np.arange(5) + i, (12 + i) % 2 == 0)\n",
    "assert _buffer.mem_size == 10\n",
    "assert _buffer.mem_cntr == 10, \"Wrong mem_cntr\"\n",
    "\n",
    "_is = set()\n",
    "for s, a, r, s_, t in zip(*_buffer.sample_batch(5)):\n",
    "    i = s[0]\n",
    "    assert 0 <= i < 10, \"Wrong states\"\n",
    "    _is.add(i)\n",
    "    np.testing.assert_array_equal(s, np.arange(5) + i, err_msg=\"Wrong states\")\n",
    "    np.testing.assert_equal(a, 5 + i, err_msg=\"Wrong actions\")\n",
    "    np.testing.assert_equal(r, 6 + i, err_msg=\"Wrong rewards\")\n",
    "    np.testing.assert_array_equal(s_, 7 + np.arange(5) + i, err_msg=\"Wrong next states\")\n",
    "    np.testing.assert_equal(t, (12 + i) % 2 == 0, err_msg=\"Wrong terminals\")\n",
    "assert len(_is) == 5, \"Duplicate transitions\"\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### b) Fill replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Initialize replay buffer\n",
    "buffer = ReplayBuffer(mem_size=25000, state_shape=env.observation_space.shape)\n",
    "\n",
    "# ********************\n",
    "# TODO Sample transitions from environment and add to buffer\n",
    "\n",
    "while not buffer.is_filled():\n",
    "    state = env.reset()\n",
    "    actt = env.action_space.sample()\n",
    "    next_state, reward, terminal,_ = env.step(actt)\n",
    "    buffer.add(state,actt,reward,next_state,terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code\n",
    "assert buffer.is_filled(), f\"Buffer not filled, only {buffer.mem_cntr}/{buffer.mem_size} transitions in memory\"\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question B2 - Deep Q-Networks\n",
    "### a) Define Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        # TODO Create layers\n",
    "        self.mlp1 = nn.Linear(4,256)\n",
    "        self.mlp2 = nn.Linear(256,2)\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        # TODO Implement forward pass\n",
    "        x = torch.relu(self.mlp1(state))\n",
    "        x = self.mlp2(x)\n",
    "        Q = F.softmax(x,dim=-1)\n",
    "\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code\n",
    "_test_output = DeepQNetwork()(torch.FloatTensor([[1, 2, 3, 4]]))\n",
    "assert _test_output.shape == (1, 2), f\"Expected output shape (1, 2), got {_test_output.shape}\"\n",
    "\"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### b) $\\epsilon$-Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy(state, q_network, epsilon=0.05):\n",
    "    \"\"\"Perform epsilon-greedy action sampling.\n",
    "\n",
    "    Args:\n",
    "        state: numpy ndarray, current state\n",
    "        q_network: torch module\n",
    "\n",
    "    Returns:\n",
    "        action: one action\n",
    "    \"\"\"\n",
    "    # TODO Epsilon-greedy action sampling\n",
    "    flag = 555\n",
    "    poss_action = DeepQNetwork()(torch.FloatTensor(state)).detach().numpy()\n",
    "    test = np.random.rand()\n",
    "    if test < epsilon:\n",
    "        flag = 999\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(poss_action)\n",
    "    print(action,flag)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 999\n",
      "0 999\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "1 999\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "0 999\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "1 999\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 999\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 555\n",
      "0 999\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 999\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 555\n",
      "1 999\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "0 555\n",
      "1 999\n",
      "1 999\n",
      "1 999\n",
      "1 555\n",
      "0 555\n",
      "0 999\n",
      "0 555\n",
      "0 555\n",
      "1 555\n",
      "1 555\n",
      "1 555\n",
      "518\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Frequency of action 0 (482) is outside the 99% confidence interval [76, 124]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m _zeros \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(_actions)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Note: This is a stochastic test. It produces a false error in 1% of the cases\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m75\u001b[39m \u001b[38;5;241m<\u001b[39m _zeros \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m125\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency of action 0 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_zeros\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is outside the 99% confidence interval [76, 124]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Frequency of action 0 (482) is outside the 99% confidence interval [76, 124]"
     ]
    }
   ],
   "source": [
    "# Test Code\n",
    "class DummyModule(nn.Module):\n",
    "    def forward(self, state):\n",
    "        return torch.FloatTensor([1, 2])  # Constant output\n",
    "\n",
    "\n",
    "# Sample 1000 actions\n",
    "_actions = [epsilon_greedy(np.array([1, 2, 3, 4]), DummyModule(), epsilon=0.2) for _ in range(1000)]\n",
    "# print(type(_actions[0]),type(_actions[1]),type(_actions[2]))\n",
    "print(sum(_actions))\n",
    "\n",
    "sns.histplot(_actions, discrete=True, stat=\"density\")\n",
    "plt.xticks([0, 1])\n",
    "plt.show()\n",
    "\n",
    "_zeros = 1000 - sum(_actions)\n",
    "# Note: This is a stochastic test. It produces a false error in 1% of the cases\n",
    "assert 75 < _zeros < 125, f\"Frequency of action 0 ({_zeros}) is outside the 99% confidence interval [76, 124]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### c) Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()\n",
    "\n",
    "def compute_loss(q_network, target_network, states, actions, rewards, next_states, is_terminal, gamma=0.99):\n",
    "    # TODO Implement loss function\n",
    "    qvals = q_network(torch.FloatTensor(states)).detach().numpy() * (1-is_terminal)\n",
    "    best_q = np.max(q_network(torch.FloatTensor(next_states)).detach().numpy()) * (1-is_terminal)\n",
    "    targetqvals = target_network(torch.FloatTensor(next_states)).detach().numpy() * (1-is_terminal)  \n",
    "    best_targetq = np.max(expected_qvals) * (1-is_terminal)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    expected_qvals = reward + gamma*best_targetq\n",
    "    loss = mse(qvals, expected_qvals)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### d) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a718479159141cd9ab0f0bcf041c564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 555\n",
      "0 555\n",
      "0 555\n",
      "0 555\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m terminal_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mBoolTensor(terminal_batch)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminal_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(q_network, target_network, states, actions, rewards, next_states, is_terminal, gamma)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(q_network, target_network, states, actions, rewards, next_states, is_terminal, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# TODO Implement loss function\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     qvals \u001b[38;5;241m=\u001b[39m q_network(torch\u001b[38;5;241m.\u001b[39mFloatTensor(states))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mis_terminal\u001b[49m)\n\u001b[1;32m      6\u001b[0m     best_q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(q_network(torch\u001b[38;5;241m.\u001b[39mFloatTensor(next_states))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mis_terminal)\n\u001b[1;32m      7\u001b[0m     targetqvals \u001b[38;5;241m=\u001b[39m target_network(torch\u001b[38;5;241m.\u001b[39mFloatTensor(next_states))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mis_terminal)  \n",
      "File \u001b[0;32m~/anaconda3/envs/Coding/lib/python3.10/site-packages/torch/_tensor.py:31\u001b[0m, in \u001b[0;36m_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Coding/lib/python3.10/site-packages/torch/_tensor.py:604\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__rsub__\u001b[39m, (\u001b[38;5;28mself\u001b[39m, other), \u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epsilon = 0.05  # For epsilon greedy action sampling\n",
    "batch_size = 64\n",
    "NETWORK_UPDATE_FREQUENCY = 4\n",
    "NETWORK_SYNC_FREQUENCY = 2000\n",
    "gamma = 0.99\n",
    "episodes = 10000\n",
    "replay_buffer_size = 0 #TODO\n",
    "\n",
    "\n",
    "q_network = DeepQNetwork()\n",
    "target_network = deepcopy(q_network)\n",
    "optimizer = torch.optim.Adam(q_network.parameters(), lr=1e-3)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "step_count = 0\n",
    "total_rewards = []\n",
    "with tqdm(range(episodes)) as pbar:\n",
    "    for _ in pbar:\n",
    "        state, done = env.reset(), False\n",
    "        rewards = []\n",
    "\n",
    "        while not done:\n",
    "            # Take a step\n",
    "            action = epsilon_greedy(state, q_network, epsilon=epsilon)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Bookkeeping\n",
    "            rewards.append(reward)\n",
    "            buffer.add(state=state, action=action, reward=reward, next_state=next_state, is_terminal=done and env._elapsed_steps < 500)\n",
    "            state = next_state\n",
    "\n",
    "            step_count += 1\n",
    "\n",
    "            # Update network every NETWORK_UPDATE_FREQUENCY steps\n",
    "            if step_count % NETWORK_UPDATE_FREQUENCY == 0:\n",
    "                # Sample batch of transitions\n",
    "                state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = buffer.sample_batch(batch_size=batch_size)\n",
    "                state_batch = torch.FloatTensor(state_batch)\n",
    "                next_state_batch = torch.FloatTensor(next_state_batch)\n",
    "                action_batch = torch.LongTensor(action_batch).reshape(-1, 1)\n",
    "                reward_batch = torch.FloatTensor(reward_batch).reshape(-1, 1)\n",
    "                terminal_batch = torch.BoolTensor(terminal_batch)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = compute_loss(q_network, target_network, state_batch, action_batch, reward_batch, next_state_batch, terminal_batch, gamma)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "           \n",
    "            # Sync networks every NETWORK_SYNC_FREQUENCY steps\n",
    "            if step_count % NETWORK_SYNC_FREQUENCY == 0:\n",
    "                # ********************\n",
    "                # TODO Synchronize networks\n",
    "                target_network = deepcopy(q_network)\n",
    "\n",
    "\n",
    "\n",
    "                # ********************\n",
    "\n",
    "        total_rewards.append(sum(rewards))\n",
    "\n",
    "         # Print statistics\n",
    "        pbar.set_description(f\"Mean training reward {np.mean(total_rewards[-100:]):.02f}\")\n",
    "        if np.mean(total_rewards[-100:]) == 500:\n",
    "            break # Stop training\n",
    "\n",
    "# Save model\n",
    "with open(\"solution/b2d.pt\", \"wb\") as f:\n",
    "    torch.save(q_network, f)\n",
    "\n",
    "# Plot training\n",
    "plt.plot(total_rewards, label=\"per episode\")\n",
    "plt.plot(pd.DataFrame(total_rewards).rolling(100).mean(), label=\"average reward\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"solution/b2d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b2968e57ce416f92167013e5194a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "CartPoleEnv.reset() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39m_elapsed_steps\n\u001b[0;32m---> 16\u001b[0m _avg_reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([_rollout(seed\u001b[38;5;241m=\u001b[39mi) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _avg_reward \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m487.5\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage reward below 487.5, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_avg_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok (Average reward \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_avg_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39m_elapsed_steps\n\u001b[0;32m---> 16\u001b[0m _avg_reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[43m_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _avg_reward \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m487.5\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage reward below 487.5, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_avg_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok (Average reward \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_avg_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m_rollout\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rollout\u001b[39m(seed):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     state, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(), \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n",
      "File \u001b[0;32m~/anaconda3/envs/Coding/lib/python3.10/site-packages/gym/wrappers/time_limit.py:27\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: CartPoleEnv.reset() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "policy = q_network\n",
    "policy.eval()  # Switch to evaluation mode\n",
    "\n",
    "\n",
    "def _rollout(seed):\n",
    "    env.reset(seed=seed)\n",
    "    state, done = env.reset(), False\n",
    "    while not done:\n",
    "        probs = policy(torch.tensor(state).float().reshape((1, -1)))[0]\n",
    "        action = np.argmax(probs.detach().numpy())  # Greedy action\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    return env._elapsed_steps\n",
    "\n",
    "\n",
    "_avg_reward = np.mean([_rollout(seed=i) for i in tqdm(range(100), desc=\"Validating\")])\n",
    "assert _avg_reward >= 487.5, f\"Average reward below 487.5, got {_avg_reward}\"\n",
    "f\"ok (Average reward {_avg_reward:0.2f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
